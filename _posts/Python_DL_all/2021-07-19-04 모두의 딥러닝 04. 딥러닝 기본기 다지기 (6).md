---
title: "[Python] 모두의 딥러닝 - 04. 딥러닝 기본기 다지기[선형 회귀]"
excerpt: "선형 회귀를 딥러닝 모델로 만들기"
categories: 
  - DL_all
tags: 
    - Python
    - DL_all
toc: TRUE
toc_sticky: TRUE
use_math: TRUE
---


**모두의 딥러닝** 교재를 토대로 공부한 내용입니다.

실습과정에서 필요에 따라 코드나 이론에 대한 추가, 수정사항이 있습니다.

---

**기본 세팅**


```python
import numpy as np
import pandas as pd

import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
```


```python
%matplotlib inline
%config InlineBackend.figure_format = 'retina'

mpl.rc('font', family='NanumGothic') # 폰트 설정
mpl.rc('axes', unicode_minus=False) # 유니코드에서 음수 부호 설정

# 차트 스타일 설정
sns.set(font="NanumGothic", rc={"axes.unicode_minus":False}, style='darkgrid')
plt.rc("figure", figsize=(10,8))

warnings.filterwarnings("ignore")
```

---

# 15. 선형 회귀 적용

이번 챕터에서는 분류가 아닌 선형 회귀 문제를 해결해보자.

## 15.1 데이터 불러오기

실습에 사용할 데이터는 boston 주택 가격 데이터를 사용한다.

데이터의 구조는 다음과 같다.

|피처번호| 변수명 | 설명 |
|-|-|-|
|0|CRIM|범죄율
|1|ZN|25,000 평방피트를 초과 거주지역 비율
|2|INDUS|비소매상업지역 면적 비율
|3|CHAS|찰스강의 경계에 위치한 경우는 1, 아니면 0
|4|NOX|일산화질소 농도 
|5|RM|주택당 방 수
|6|AGE|1940년 이전에 건축된 주택의 비율
|7|DIS|직업센터의 거리
|8|RAD|방사형 고속도로까지의 거리
|9|TAX|재산세율
|10|PTRATIO|학생/교사 비율
|11|B|인구 중 흑인 비율
|12|LSTAT|인구 중 하위 계층 비율
|13|MEDV|보스턴 506개 타운의 1978년 주택 가격 중앙값 (단위 1,000 달러)


```python
# df = pd.read_csv("deeplearning/dataset/housing.csv", header=None, delim_whitespace=True)
df = pd.read_csv("deeplearning/dataset/housing.csv", header=None, sep="\s+") # space +s
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
  </tbody>
</table>
</div>



- 데이터는 공백으로 구분되어 있다.


- 단, 하나의 공백인 경우도 있고 여러개의 공백인 경우도 있어 이런 경우 +를 붙여준다.

## 15.2 모델 설정


```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# 모델 설정
model = Sequential()
model.add(Dense(30, input_dim=13, activation="relu"))
model.add(Dense(6, activation="relu"))
model.add(Dense(1))
```

- 선형 회귀에선 마지막에 분류를 할 필요가 없으므로 활성화 함수를 지정할 필요가 없다.


- 마지막에 활성화 함수 없이 1개의 값을 출력하는 것을 잘 기억해두자.

## 15.3 모델 실행


```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import tensorflow as tf
from sklearn.model_selection import train_test_split

# 시드 설정
np.random.seed(0)
tf.random.set_seed(0)

# 데이터 분리
datasets = df.values
X = datasets[:,:13]
Y = datasets[:,13]

# train, test 분리
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)

# 모델 설정
model = Sequential()
model.add(Dense(30, input_dim=13, activation="relu"))
model.add(Dense(6, activation="relu"))
model.add(Dense(1))

# 모델 컴파일
model.compile(loss="mean_squared_error", optimizer="adam")

# 모델 실행
model.fit(X_train, Y_train, 
          epochs=200, batch_size=10, 
          verbose=1)
```

    Train on 354 samples
    Epoch 1/200
    354/354 [==============================] - 0s 1ms/sample - loss: 8288.7420
    Epoch 2/200
    354/354 [==============================] - 0s 106us/sample - loss: 670.3109
    Epoch 3/200
    354/354 [==============================] - 0s 101us/sample - loss: 498.1099
    ...
    Epoch 198/200
    354/354 [==============================] - 0s 95us/sample - loss: 16.9992
    Epoch 199/200
    354/354 [==============================] - 0s 98us/sample - loss: 16.8569
    Epoch 200/200
    354/354 [==============================] - 0s 98us/sample - loss: 17.8330
    




    <tensorflow.python.keras.callbacks.History at 0x212df40f148>



- 교재에선 `keras`의 `Sequential()`과 `Dense()`를 사용한다.


- 나는 `tensorflow`를 사용하고 있어서 seed를 같이 주어도 값이 다르게 나타난다.


- 그런데 이 모델을 계속 실행하다보니 loss가 너무 커서 추후 예측시 어떤 값을 넣어도 같은 값을 예측하였다.


- 교재 코드는 예측 값이 잘 나타났으나 seed를 바꿔보니 역시나 경우에 따라 같은 값을 예측하였다..;


- 결과창이 너무 길어 직접 삭제해두었다.

```python
# 예측 값
Y_pred = model.predict(X_test).reshape(-1)

# 실제 값과 비교
for i in range(10):
    y_target = Y_test[i]
    prediction = Y_pred[i]
    print(f"실제 가격: {y_target}, 예상 가격: {prediction:.1f}")
```

    실제 가격: 22.6, 예상 가격: 24.9
    실제 가격: 50.0, 예상 가격: 25.0
    실제 가격: 23.0, 예상 가격: 24.5
    실제 가격: 8.3, 예상 가격: 11.5
    실제 가격: 21.2, 예상 가격: 17.8
    실제 가격: 19.9, 예상 가격: 20.6
    실제 가격: 20.6, 예상 가격: 22.5
    실제 가격: 18.7, 예상 가격: 21.9
    실제 가격: 16.1, 예상 가격: 16.3
    실제 가격: 18.6, 예상 가격: 8.1
    

- 앞서 loss가 작게 나오는 seed를 찾아서 실행하여 결과는 잘 나타난다.


- 이번 문제를 구글링을 하니 다른 사람들은 또 선형 회귀 모델 설정 방식이 많이 달랐다.


- 아무래도 교재가 거의 기본서 개념이라 쉬운 방법으로 소개 받는다고만 생각해야겠다.
